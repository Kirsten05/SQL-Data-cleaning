# SQL-Data-cleaning
This project focuses on cleaning and preparing a global layoffs dataset spanning 2019 to 2022 using SQL. The goal was to transform raw, inconsistent data into a reliable foundation for analysis and visualization.


What I Did
- Removed duplicates and handled missing values to ensure data integrity
- Standardized company names, industries, and location formats for consistency
- Parsed and reformatted date fields to enable time-series analysis
- Normalized categorical variables for easier grouping and filtering
- Created derived columns (e.g., year, month, continent) to enrich the dataset
- Filtered out irrelevant entries and corrected anomalies in reported layoff numbers
- Documented the cleaning process with clear SQL scripts and comments
  

Why It Matters
Clean data is the backbone of any meaningful analysis. This dataset is now ready for:
- Trend analysis across years and regions
- Industry-specific impact studies
- Visualization in BI tools like Power BI or Tableau
- Feeding into machine learning models for predictive insights
